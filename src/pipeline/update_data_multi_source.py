"""
å¢é‡æ›´æ–°æ•°æ® - ä½¿ç”¨å¤šæ•°æ®æºç³»ç»Ÿ
è‡ªåŠ¨å°è¯•å¤šä¸ªå…è´¹æ•°æ®æºï¼Œç›¸äº’è¡¥å……
"""
import argparse
import logging
import sys
from datetime import datetime, timedelta
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.data.multi_providers import create_multi_source_client
import pandas as pd

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s - %(message)s"
)
logger = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(description="æ›´æ–°è‚¡ç¥¨æ•°æ® (å¤šæ•°æ®æºå¢é‡æ›´æ–°)")
    parser.add_argument("symbol", help="è‚¡ç¥¨ä»£ç  (ä¾‹å¦‚: TSLA)")
    parser.add_argument("--days", type=int, default=30, help="æ›´æ–°æœ€è¿‘Nå¤©çš„æ•°æ® (é»˜è®¤30å¤©)")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = project_root / "data" / f"sample_{args.symbol.lower()}.csv"
    
    logger.info("=" * 70)
    logger.info(f"ğŸ“Š æ›´æ–° {args.symbol} æ•°æ® (å¤šæ•°æ®æºæ¨¡å¼)")
    logger.info("=" * 70)
    
    # ç¡®å®šæ›´æ–°çš„æ—¥æœŸèŒƒå›´
    start_date = None
    end_date = datetime.now().date()
    
    if output_path.exists():
        try:
            existing_data = pd.read_csv(output_path)
            if not existing_data.empty:
                # è·å–æœ€åæ—¥æœŸ
                last_date_str = existing_data.iloc[-1]['date']
                last_date = datetime.strptime(last_date_str, '%Y-%m-%d').date()
                days_since = (end_date - last_date).days
                
                logger.info(f"ğŸ“‚ ç°æœ‰æ•°æ®æœ€æ–°æ—¥æœŸ: {last_date} ({days_since}å¤©å‰)")
                
                if days_since <= 1:
                    logger.info("âœ“ æ•°æ®å·²æ˜¯æœ€æ–°,æ— éœ€æ›´æ–°")
                    print("\nâœ“ æ•°æ®å·²æ˜¯æœ€æ–°!")
                    return
                
                # ä»æœ€åæ—¥æœŸçš„åä¸€å¤©å¼€å§‹æ›´æ–°
                start_date = last_date + timedelta(days=1)
                logger.info(f"ğŸ“… å¢é‡æ›´æ–°: {start_date} è‡³ {end_date}")
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•è¯»å–ç°æœ‰æ•°æ®: {e}")
            start_date = end_date - timedelta(days=args.days)
    else:
        # é¦–æ¬¡ä¸‹è½½
        start_date = end_date - timedelta(days=args.days)
        logger.info(f"ğŸ“… é¦–æ¬¡ä¸‹è½½æœ€è¿‘ {args.days} å¤©æ•°æ®")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
    if start_date > end_date:
        logger.info("âœ“ æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
        print("\nâœ“ æ•°æ®å·²æ˜¯æœ€æ–°!")
        return
    
    logger.info("")
    logger.info("ğŸŒ ä½¿ç”¨å¤šæ•°æ®æºç³»ç»Ÿè·å–æ•°æ®")
    logger.info("   å°†è‡ªåŠ¨å°è¯•: Yahoo Finance â†’ Alpha Vantage â†’ Twelve Data")
    logger.info("")
    
    # è·å–æ•°æ®
    try:
        client = create_multi_source_client()
        fetched = client.fetch_daily_history(
            symbol=args.symbol,
            start=start_date,
            end=end_date
        )
        
        if fetched.empty:
            logger.error("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            print("\nâŒ æ•°æ®è·å–å¤±è´¥ï¼Œæœªè·å–åˆ°ä»»ä½•æ•°æ®")
            sys.exit(1)
        
        # æ ‡å‡†åŒ–æ ¼å¼
        fetched['date'] = fetched['date'].astype(str)
        fetched[['open', 'high', 'low', 'close']] = fetched[['open', 'high', 'low', 'close']].astype(float)
        fetched['volume'] = fetched['volume'].astype(int)
        
        logger.info(f"âœ“ æˆåŠŸè·å– {len(fetched)} æ¡æ–°æ•°æ®")
        logger.info(f"  æ—¥æœŸèŒƒå›´: {fetched.iloc[0]['date']} è‡³ {fetched.iloc[-1]['date']}")
        
        # åˆå¹¶æ•°æ®
        if output_path.exists():
            existing = pd.read_csv(output_path)
            combined = pd.concat([existing, fetched], ignore_index=True)
            logger.info(f"  åˆå¹¶å‰: {len(existing)} æ¡")
        else:
            combined = fetched
            logger.info("  æ–°å»ºæ•°æ®æ–‡ä»¶")
        
        # å»é‡å¹¶æ’åº
        combined.drop_duplicates(subset='date', keep='last', inplace=True)
        combined.sort_values(by='date', inplace=True)
        
        # ä¿å­˜
        output_path.parent.mkdir(parents=True, exist_ok=True)
        combined.to_csv(output_path, index=False)
        
        logger.info("")
        logger.info("=" * 70)
        logger.info("âœ… æ•°æ®æ›´æ–°å®Œæˆ!")
        logger.info(f"   æ€»è¡Œæ•°: {len(combined)}")
        logger.info(f"   æ—¥æœŸèŒƒå›´: {combined.iloc[0]['date']} è‡³ {combined.iloc[-1]['date']}")
        logger.info(f"   ä¿å­˜è·¯å¾„: {output_path}")
        logger.info("=" * 70)
        
        print(f"\nâœ… æ•°æ®å·²æ›´æ–°åˆ°: {output_path}")
        print(f"   æ€»è¡Œæ•°: {len(combined)}")
        print(f"   æœ€æ–°æ—¥æœŸ: {combined.iloc[-1]['date']}")
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®æ›´æ–°å¤±è´¥: {e}")
        print(f"\nâŒ æ•°æ®æ›´æ–°å¤±è´¥: {e}")
        print("\nğŸ’¡ æç¤º:")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("  2. å¦‚æœæ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œå¯èƒ½é‡åˆ°APIé¢‘ç‡é™åˆ¶")
        print("  3. å¯ä»¥é…ç½®å¤‡ç”¨æ•°æ®æºçš„APIå¯†é’¥:")
        print("     - Alpha Vantage: https://www.alphavantage.co/support/#api-key")
        print("     - Twelve Data: https://twelvedata.com/pricing")
        print("  4. è®¾ç½®ç¯å¢ƒå˜é‡:")
        print("     $env:ALPHA_VANTAGE_API_KEY = 'your_key'")
        print("     $env:TWELVE_DATA_API_KEY = 'your_key'")
        sys.exit(1)


if __name__ == "__main__":
    main()
